{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will explore how to read a simple Lightning Memory-Mapped Database (LMDB) using a batch generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pyxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a small dataset of `10` samples. Each input is an image with shape `(254, 254, 3)`, while the targets are scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_samples = 10\n",
    "\n",
    "X = np.random.rand(nb_samples, 254, 254, 3)\n",
    "y = np.arange(nb_samples, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is written using the LMDB writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = pyxis.Writer(dirpath='data',\n",
    "                  input_shape=(254,254,3), target_shape=(),\n",
    "                  input_dtype=np.float32, target_dtype=np.uint8,\n",
    "                  map_size_limit=500, ram_gb_limit=1)\n",
    "db.put_samples(X, y)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the batch generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back the data using the LMDB reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = pyxis.Reader('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example 1 - Number of samples is a multiple of the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first example we create a batch generator where the number of samples is divisible by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_gen = db.batch_generator(batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artificial dataset has `10` samples, so by letting the batch size be `5` it will take *two* iterations to go through the whole dataset. The artificial targets for four batches are printed out to showcase this.\n",
    "\n",
    "`endless_mode` is by default on, which means that after having gone through the dataset, the generator will re-iterate over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0 \tTargets: [0 1 2 3 4]\n",
      "\n",
      "Iteration: 1 \tTargets: [5 6 7 8 9]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 2 \tTargets: [0 1 2 3 4]\n",
      "\n",
      "Iteration: 3 \tTargets: [5 6 7 8 9]\n",
      "We have reached the end of the dataset\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    xs, ys = next(batch_gen)\n",
    "    print()\n",
    "    print('Iteration:', i, '\\tTargets:', ys)\n",
    "    if db.end_of_dataset:\n",
    "        print('We have reached the end of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Number of samples is not a multiple of the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_gen = db.batch_generator(batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artificial dataset has `10` samples, so by letting the batch size be `3` it will take four iterations to go through the whole dataset. The artificial targets for *six* batches are printed out to showcase this.\n",
    "\n",
    "Notice that the final batch of the dataset only contains the remaining unseen samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0 \tTargets: [0 1 2]\n",
      "\n",
      "Iteration: 1 \tTargets: [3 4 5]\n",
      "\n",
      "Iteration: 2 \tTargets: [6 7 8]\n",
      "\n",
      "Iteration: 3 \tTargets: [9]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 4 \tTargets: [0 1 2]\n",
      "\n",
      "Iteration: 5 \tTargets: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    xs, ys = next(batch_gen)\n",
    "    print()\n",
    "    print('Iteration:', i, '\\tTargets:', ys)\n",
    "    if db.end_of_dataset:\n",
    "        print('We have reached the end of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 - Shuffling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have created batches by reading samples from the dataset in the order they were written. However, by turning shuffling on, the samples in the dataset will be reshuffled each time we go through the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_gen = db.batch_generator(batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0 \tTargets: [2 7 4 6 1]\n",
      "\n",
      "Iteration: 1 \tTargets: [9 0 3 8 5]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 2 \tTargets: [0 8 2 5 9]\n",
      "\n",
      "Iteration: 3 \tTargets: [1 7 3 6 4]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 4 \tTargets: [8 0 4 9 1]\n",
      "\n",
      "Iteration: 5 \tTargets: [7 2 5 3 6]\n",
      "We have reached the end of the dataset\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    xs, ys = next(batch_gen)\n",
    "    print()\n",
    "    print('Iteration:', i, '\\tTargets:', ys)\n",
    "    if db.end_of_dataset:\n",
    "        print('We have reached the end of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4 - Stochastic batch generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batches can be created stochastically. This means that the samples in a batch are sampled uniformly from the entire dataset. Here we showcase *ten* different batches with a batch size of *five*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbg = db.stochastic_batch_generator(batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \tTargets: [9 7 4 6 7]\n",
      "Iteration: 1 \tTargets: [6 3 1 0 2]\n",
      "Iteration: 2 \tTargets: [0 9 9 5 8]\n",
      "Iteration: 3 \tTargets: [1 5 0 1 6]\n",
      "Iteration: 4 \tTargets: [6 4 6 6 7]\n",
      "Iteration: 5 \tTargets: [6 1 6 0 5]\n",
      "Iteration: 6 \tTargets: [2 1 4 5 7]\n",
      "Iteration: 7 \tTargets: [4 3 4 4 6]\n",
      "Iteration: 8 \tTargets: [1 9 6 8 6]\n",
      "Iteration: 9 \tTargets: [7 3 7 9 9]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    xs, ys = next(sbg)\n",
    "    print('Iteration:', i, '\\tTargets:', ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5 - Sequential batch generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batches can be created by reading the database sequentially. This means that the samples in a batch are not shuffled, but can be read in higher speed.\n",
    "Sequential batch generator is ideal for very large datasets. Here we showcase ten different batches with a batch size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = db.sequential_batch_generator(batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \tTargets: [0 1 2]\n",
      "Iteration: 1 \tTargets: [3 4 5]\n",
      "Iteration: 2 \tTargets: [6 7 8]\n",
      "Iteration: 3 \tTargets: [9]\n",
      "Iteration: 4 \tTargets: [0 1 2]\n",
      "Iteration: 5 \tTargets: [3 4 5]\n",
      "Iteration: 6 \tTargets: [6 7 8]\n",
      "Iteration: 7 \tTargets: [9]\n",
      "Iteration: 8 \tTargets: [0 1 2]\n",
      "Iteration: 9 \tTargets: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    xs, ys = next(seq)\n",
    "    print('Iteration:', i, '\\tTargets:', ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the two types of Python batch generators demonstrated above will always yield inputs and targets as they were stored in the LMDB. To relax this constraint the package comes bundled with a generic *thread-safe* Python iterator which make it easy to modify data in a batch. By *thread-safe* we mean that when more than one thread make use of the iterator it will not raise an exception.\n",
    "\n",
    "Below is a straightforward example that makes use of the ``SimpleBatchIterator``. It is simply a wrapper around the Python generator seen above. We only go through the data once with a batch size of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "[0 1]\n",
      "[2 3]\n",
      "[4 5]\n",
      "[6 7]\n",
      "[8 9]\n"
     ]
    }
   ],
   "source": [
    "batch_iter = pyxis.SimpleBatchIterator(db, batch_size=2, shuffle=False, endless_mode=False)\n",
    "\n",
    "print('Targets:')\n",
    "for x, y in batch_iter:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an iterator that modifies the data we can, for example, modify one of the existing iterators using inheritance. Here is an example where all *targets* are squared before they are output by the iterator. Notice how thread-safety is achieved by using the ``with`` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SquareTargets(pyxis.SimpleBatchIterator):\n",
    "    def __init__(self, db_reader, batch_size):\n",
    "        super(SquareTargets, self).__init__(db_reader, batch_size,\n",
    "                                            shuffle=False, endless_mode=False)\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            X, y = next(self.batch_gen)\n",
    "\n",
    "        y = y ** 2\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``SquareTargets`` can now be used to generate batches of data from the LMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared targets:\n",
      "[0 1]\n",
      "[4 9]\n",
      "[16 25]\n",
      "[36 49]\n",
      "[64 81]\n"
     ]
    }
   ],
   "source": [
    "batch_iter = SquareTargets(db, batch_size=2)\n",
    "\n",
    "print('Squared targets:')\n",
    "for x, y in batch_iter:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure to close the LMDB environment after we are done reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
